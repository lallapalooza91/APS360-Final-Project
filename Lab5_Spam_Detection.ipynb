{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lallapalooza91/APS360-Final-Project/blob/main/Lab5_Spam_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bphECiUa9zw"
      },
      "source": [
        "# Lab 5: Spam Detection\n",
        "\n",
        "In this assignment, we will build a recurrent neural network to classify a SMS text message\n",
        "as \"spam\" or \"not spam\". In the process, you will\n",
        "    \n",
        "1. Clean and process text data for machine learning.\n",
        "2. Understand and implement a character-level recurrent neural network.\n",
        "3. Use torchtext to build recurrent neural network models.\n",
        "4. Understand batching for a recurrent neural network, and use torchtext to implement RNN batching.\n",
        "\n",
        "### What to submit\n",
        "\n",
        "Submit a PDF file containing all your code, outputs, and write-up. You can produce a PDF of your Google Colab file by going to File > Print and then save as PDF. The Colab instructions have more information.\n",
        "\n",
        "Do not submit any other files produced by your code.\n",
        "\n",
        "Include a link to your colab file in your submission."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "jupyter nbconvert --to html \"/content/Lab5_Spam_Detection.ipynb\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2IIkYDNaz-G",
        "outputId": "f52f3622-eded-4b82-fbca-d08dc0588256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook /content/Lab5_Spam_Detection.ipynb to html\n",
            "[NbConvertApp] Writing 757097 bytes to /content/Lab5_Spam_Detection.html\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWiUqJJTa9z6"
      },
      "source": [
        "## Colab Link\n",
        "\n",
        "Include a link to your Colab file here. If you would like the TA to look at your\n",
        "Colab file in case your solutions are cut off, **please make sure that your Colab\n",
        "file is publicly accessible at the time of submission**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuYLc7fLDYTH"
      },
      "source": [
        "Colab Link: https://colab.research.google.com/drive/1lz6NAXXNYZwA0PTqaQ_ZHCFCQLqZqQrm?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9ag64zDDYTI"
      },
      "source": [
        "As we are using the older version of the torchtext, please run the following to downgrade the torchtext version:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U torch==1.8.0+cu111 torchtext==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9uLhP_eDeVI",
        "outputId": "b2e7f028-a382-404a-f195-1e36fcc7ebd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp39-cp39-linux_x86_64.whl (1982.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m823.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchtext==0.9.0\n",
            "  Downloading torchtext-0.9.0-cp39-cp39-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.8.0+cu111) (4.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torch==1.8.0+cu111) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torchtext==0.9.0) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchtext==0.9.0) (2.25.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.9.0) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.9.0) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.9.0) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.9.0) (2022.12.7)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.14.1\n",
            "    Uninstalling torchtext-0.14.1:\n",
            "      Successfully uninstalled torchtext-0.14.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.14.1+cu116 requires torch==1.13.1, but you have torch 1.8.0+cu111 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.8.0+cu111 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.8.0+cu111 torchtext-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_gv57cdDYTI"
      },
      "source": [
        "!pip install -U torch==1.8.0+cu111 torchtext==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iHmoOqJDYTJ"
      },
      "source": [
        "If you are interested to use the most recent version if torchtext, you can look at the following document to see how to convert the legacy version to the new version:\n",
        "https://colab.research.google.com/github/pytorch/text/blob/master/examples/legacy_tutorial/migration_tutorial.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgfNOUaPa9z8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0jLI9LBa90C"
      },
      "source": [
        "## Part 1. Data Cleaning [15 pt]\n",
        "\n",
        "We will be using the \"SMS Spam Collection Data Set\" available at http://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n",
        "\n",
        "There is a link to download the \"Data Folder\" at the very top of the webpage. Download the zip file, unzip it, and upload the file `SMSSpamCollection` to Colab.    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSuF7C_Ga90E"
      },
      "source": [
        "### Part (a) [2 pt]\n",
        "\n",
        "Open up the file in Python, and print out one example of a spam SMS, and one example of a non-spam SMS.\n",
        "\n",
        "What is the label value for a spam message, and what is the label value for a non-spam message?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_IfXHeTa90F",
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50300ab6-c5bf-4944-8fe0-613bf390893f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: ham | Message: Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
            "Label: ham | Message: Ok lar... Joking wif u oni...\n",
            "Label: spam | Message: Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
            "Label: ham | Message: U dun say so early hor... U c already then say...\n",
            "Label: ham | Message: Nah I don't think he goes to usf, he lives around here though\n",
            "Label: spam | Message: FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\n"
          ]
        }
      ],
      "source": [
        "i = 0\n",
        "for line in open('SMSSpamCollection'):\n",
        "    split = line.split()\n",
        "    print('Label: {} | Message: {}'.format(split[0], ' '.join(split[1:])))\n",
        "    i+=1\n",
        "    if (i > 5):\n",
        "      break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The label value for a spam message is `spam`, and the label value for non-spam message is `ham`."
      ],
      "metadata": {
        "id": "-QrVVweUTeR1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AukA6vMVa90d"
      },
      "source": [
        "### Part (b) [1 pt]\n",
        "\n",
        "How many spam messages are there in the data set?\n",
        "How many non-spam messages are there in the data set?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "LgsqyemVa90e",
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "077d35a3-cfec-4fc7-b522-a80d96af7309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 747 spam messages in the dataset\n",
            "There are 4827 non-spam messages in the dataset\n"
          ]
        }
      ],
      "source": [
        "spam = 0\n",
        "ham = 0\n",
        "for line in open('SMSSpamCollection'):\n",
        "    split = line.split()\n",
        "    if(split[0] == 'spam'):\n",
        "      spam+=1\n",
        "    if(split[0] == 'ham'):\n",
        "      ham+=1\n",
        "\n",
        "print('There are {} spam messages in the dataset'.format(spam))\n",
        "print('There are {} non-spam messages in the dataset'.format(ham))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1WXxVt6a90h"
      },
      "source": [
        "### Part (c) [4 pt]\n",
        "\n",
        "We will be using the package `torchtext` to load, process, and batch the data.\n",
        "A tutorial to torchtext is available below. This tutorial uses the same\n",
        "Sentiment140 data set that we explored during lecture.\n",
        "\n",
        "https://medium.com/@sonicboom8/sentiment-analysis-torchtext-55fb57b1fab8\n",
        "\n",
        "Unlike what we did during lecture, we will be building a **character level RNN**.\n",
        "That is, we will treat each **character** as a token in our sequence,\n",
        "rather than each **word**.\n",
        "\n",
        "Identify two advantage and two disadvantage of modelling SMS text\n",
        "messages as a sequence of characters rather than a sequence of words."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advantages:\n",
        "1. Makes it easier to handle uncommon or misspelt words. The model can still use a word even if it has been misspelt because it is broken down into its individual letters.\n",
        "2. Language independence. With character modeling, we can model any language once we have the character set (letters) for that language.\n",
        "\n",
        "Disadvantages:\n",
        "1. Training time increases. Using character modeling means there are more items in the input sequence and thus takes longer to train.\n",
        "2. Character-level modelling may not be able to capture the relationships between words, and thus the semantic meaning of the words may be lost. The model may not be able to fully understand the context of the sentence/entire piece of text."
      ],
      "metadata": {
        "id": "O6r6gHFFVbUw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ie_D0bv9a90k"
      },
      "source": [
        "### Part (d) [1 pt]\n",
        "\n",
        "We will be loading our data set using `torchtext.data.TabularDataset`. The\n",
        "constructor will read directly from the `SMSSpamCollection` file.\n",
        "\n",
        "For the data file to be read successfuly, we\n",
        "need to specify the **fields** (columns) in the file.\n",
        "In our case, the dataset has two fields:\n",
        "\n",
        "- a text field containing the sms messages,\n",
        "- a label field which will be converted into a binary label.\n",
        "\n",
        "Split the dataset into `train`, `valid`, and `test`. Use a 60-20-20 split.\n",
        "You may find this torchtext API page helpful:\n",
        "https://torchtext.readthedocs.io/en/latest/data.html#dataset\n",
        "\n",
        "Hint: There is a `Dataset` method that can perform the random split for you."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext.legacy.data as data\n",
        "from torchtext.legacy.data import TabularDataset, Dataset\n",
        "import csv"
      ],
      "metadata": {
        "id": "MdhhFdbV5vek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the fields\n",
        "text_field = data.Field(sequential=True, tokenize= lambda x:list(x), batch_first=True)\n",
        "# I converted 'spam' to 1 and 'ham' to 0\n",
        "label = data.Field(sequential=False, preprocessing=lambda x: int(x == 'spam'), use_vocab=False)\n",
        "\n",
        "# Load the dataset\n",
        "all_data = data.TabularDataset(\n",
        "    path='/content/SMSSpamCollection', format='tsv', fields=[('label', label), ('text', text_field)],\n",
        "    skip_header=False\n",
        ")"
      ],
      "metadata": {
        "id": "EAjMgEnbFuuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the data\n",
        "train_data, val_data = Dataset.split(\n",
        "    all_data,\n",
        "    split_ratio=0.6,  # 60% for training\n",
        "    stratified=True,\n",
        "    strata_field='label'\n",
        ")"
      ],
      "metadata": {
        "id": "_qN2WoAj9kiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data, test_data = Dataset.split(\n",
        "    val_data,\n",
        "    split_ratio=0.5,  # 20% each for val and test\n",
        "    stratified=True,\n",
        "    strata_field='label'\n",
        ")"
      ],
      "metadata": {
        "id": "Ki-TAYgo_ckd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6nP0Ks_a90o"
      },
      "source": [
        "### Part (e) [2 pt]\n",
        "\n",
        "You saw in part (b) that there are many more non-spam messages than spam messages.\n",
        "This **imbalance** in our training data will be problematic for training.\n",
        "We can fix this disparity by duplicating spam messages in the training set,\n",
        "so that the training set is roughly **balanced**.\n",
        "\n",
        "Explain why having a balanced training set is helpful for training our neural network.\n",
        "\n",
        "Note: if you are not sure, try removing the below code and train your mode."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A balanced training set is helpful because if there is an imbalance, the model may only learn to predict the majority class (the class with more samples) correctly and ignore the minority classes. In this case, it may predict all messages as non-spam messages. This is important in this case because we are more interested in identifying which messages are spam (minority) than non-spam (majority).\n",
        "\n",
        "If the model is trained on an imbalanced training set it may not generalize well to new data, especially examples from the minority classes.\n",
        "\n",
        "Finally, having a balanced training set improves performance of the model as it is now forced to learn more about the minority classes and thus make better predictions."
      ],
      "metadata": {
        "id": "Brbsc7g3I-BH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FWvx9_rka90p",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# save the original training examples\n",
        "old_train_examples = train_data.examples\n",
        "# get all the spam messages in `train`\n",
        "train_spam = []\n",
        "for item in train_data.examples:\n",
        "    if item.label == 1:\n",
        "        train_spam.append(item)\n",
        "# duplicate each spam message 6 more times\n",
        "train_data.examples = old_train_examples + train_spam * 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7eUmBEva90r"
      },
      "source": [
        "### Part (f) [1 pt]\n",
        "\n",
        "We need to build the vocabulary on the training data by running the below code.\n",
        "This finds all the possible character tokens in the training set.\n",
        "\n",
        "Explain what the variables `text_field.vocab.stoi` and `text_field.vocab.itos` represent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CQM8flKa90s",
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8c80f28-c236-4ff3-9655-69873875f232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7fbfbd62b9d0>>, {'<unk>': 0, '<pad>': 1, ' ': 2, 'e': 3, 'o': 4, 't': 5, 'a': 6, 'n': 7, 'r': 8, 'i': 9, 's': 10, 'l': 11, 'u': 12, 'h': 13, '0': 14, 'd': 15, '.': 16, 'c': 17, 'm': 18, 'y': 19, 'w': 20, 'p': 21, 'g': 22, 'f': 23, '1': 24, 'b': 25, '2': 26, '8': 27, 'T': 28, 'k': 29, 'v': 30, 'E': 31, 'S': 32, '5': 33, 'C': 34, 'O': 35, 'I': 36, '4': 37, '7': 38, 'N': 39, 'A': 40, 'x': 41, '3': 42, '6': 43, 'R': 44, ',': 45, '9': 46, '!': 47, 'P': 48, 'U': 49, 'M': 50, 'W': 51, 'H': 52, 'L': 53, 'D': 54, 'B': 55, 'F': 56, 'Y': 57, 'G': 58, \"'\": 59, '/': 60, '?': 61, '£': 62, '-': 63, '&': 64, ':': 65, 'V': 66, 'z': 67, 'X': 68, 'K': 69, 'j': 70, ')': 71, 'J': 72, '*': 73, '+': 74, ';': 75, '(': 76, '\"': 77, 'q': 78, 'Q': 79, '#': 80, '=': 81, '@': 82, 'Z': 83, '>': 84, 'ü': 85, '$': 86, 'Ü': 87, '<': 88, '\\x92': 89, '‘': 90, '|': 91, '[': 92, ']': 93, '_': 94, '\\x93': 95, '¡': 96, '%': 97, '’': 98, '–': 99, 'ú': 100, '“': 101, '…': 102, '\\\\': 103, '\\x96': 104, 'é': 105, '\\t': 106, '\\n': 107, '~': 108, '\\x91': 109, '^': 110, '»': 111, 'É': 112, 'è': 113})\n",
            "['<unk>', '<pad>', ' ', 'e', 'o', 't', 'a', 'n', 'r', 'i', 's', 'l', 'u', 'h', '0', 'd', '.', 'c', 'm', 'y', 'w', 'p', 'g', 'f', '1', 'b', '2', '8', 'T', 'k', 'v', 'E', 'S', '5', 'C', 'O', 'I', '4', '7', 'N', 'A', 'x', '3', '6', 'R', ',', '9', '!', 'P', 'U', 'M', 'W', 'H', 'L', 'D', 'B', 'F', 'Y', 'G', \"'\", '/', '?', '£', '-', '&', ':', 'V', 'z', 'X', 'K', 'j', ')', 'J', '*', '+', ';', '(', '\"', 'q', 'Q', '#', '=', '@', 'Z', '>', 'ü', '$', 'Ü', '<', '\\x92', '‘', '|', '[', ']', '_', '\\x93', '¡', '%', '’', '–', 'ú', '“', '…', '\\\\', '\\x96', 'é', '\\t', '\\n', '~', '\\x91', '^', '»', 'É', 'è']\n"
          ]
        }
      ],
      "source": [
        "text_field.build_vocab(train_data)\n",
        "print(text_field.vocab.stoi)\n",
        "print(text_field.vocab.itos)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "build_vocab is a function in PyTorch's torchtext library that is used to create the vocabulary for text data. It takes a dataset as input and returns a vocabulary object that can be used to map words to unique integer IDs.\n",
        "\n",
        "`text_field.vocab.stoi` is a dictionary that maps each unique character from the vocabulary created by `build_vocab` (obtained from all the messages in the training data in this case) to a corresponding index.\n",
        "\n",
        "`text_field.vocab.itos` is a list of all the unique characters in the messages, organized by their index from `text_field.vocab.stoi`.\n"
      ],
      "metadata": {
        "id": "sZ-WrPvTKM5l"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TC8WVE8Ua90u"
      },
      "source": [
        "### Part (g) [2 pt]\n",
        "\n",
        "The tokens `<unk>` and `<pad>` were not in our SMS text messages.\n",
        "What do these two values represent?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`<unk>` stands for \"unknown\" and `<pad>` stands for \"padding\".\n",
        "\n",
        "`<unk>` is assigned to any letter that is not present in the vocabulary, that may appear in testing/inference.\n",
        "\n",
        "`<pad>` is used to pad the character sequences (or sentences) to a fixed length. All sentences in a batch are padded with this token at the end if necessary so that they all have the same length to pass to the network."
      ],
      "metadata": {
        "id": "nmAv-gUDK4Sx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff5CNk7Qa90y"
      },
      "source": [
        "### Part (h) [2 pt]\n",
        "\n",
        "Since text sequences are of variable length, `torchtext` provides a `BucketIterator` data loader,\n",
        "which batches similar length sequences together. The iterator also provides functionalities to\n",
        "pad sequences automatically.\n",
        "\n",
        "Take a look at 10 batches in `train_iter`. What is the maximum length of the\n",
        "input sequence in each batch? How many `<pad>` tokens are used in each of the 10\n",
        "batches?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "V8N8qLWOa90y",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "train_iter = data.BucketIterator(train_data,\n",
        "                                           batch_size=32,\n",
        "                                           sort_key=lambda x: len(x.text), # to minimize padding\n",
        "                                           sort_within_batch=True,        # sort within each batch\n",
        "                                           repeat=False)                  # repeat the iterator for many epochs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for batch in train_iter:\n",
        "    i+=1\n",
        "    pad_count = 0\n",
        "    max_length = len(batch.text[0])\n",
        "    print(\"Batch {}:\".format(i))\n",
        "    print('Maximum length of input sequence: {}'.format(max_length))\n",
        "    for j in range(0,len(batch.text)):\n",
        "      # count the pad tokens in each tensor\n",
        "      pad_count += (batch.text[j] == 1).sum().item()\n",
        "    print('Number of pad tokens: {}\\n'.format(pad_count))\n",
        "    # look at 10 batches\n",
        "    if (i>9):\n",
        "      break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3TxGTShNqaI",
        "outputId": "a205b5e3-9600-42cf-f048-bfcb837d2219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1:\n",
            "Maximum length of input sequence: 148\n",
            "Number of pad tokens: 24\n",
            "\n",
            "Batch 2:\n",
            "Maximum length of input sequence: 45\n",
            "Number of pad tokens: 12\n",
            "\n",
            "Batch 3:\n",
            "Maximum length of input sequence: 36\n",
            "Number of pad tokens: 32\n",
            "\n",
            "Batch 4:\n",
            "Maximum length of input sequence: 126\n",
            "Number of pad tokens: 13\n",
            "\n",
            "Batch 5:\n",
            "Maximum length of input sequence: 171\n",
            "Number of pad tokens: 158\n",
            "\n",
            "Batch 6:\n",
            "Maximum length of input sequence: 96\n",
            "Number of pad tokens: 61\n",
            "\n",
            "Batch 7:\n",
            "Maximum length of input sequence: 56\n",
            "Number of pad tokens: 38\n",
            "\n",
            "Batch 8:\n",
            "Maximum length of input sequence: 149\n",
            "Number of pad tokens: 0\n",
            "\n",
            "Batch 9:\n",
            "Maximum length of input sequence: 59\n",
            "Number of pad tokens: 51\n",
            "\n",
            "Batch 10:\n",
            "Maximum length of input sequence: 44\n",
            "Number of pad tokens: 38\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7HnqP6_a904"
      },
      "source": [
        "## Part 2. Model Building [8 pt]\n",
        "\n",
        "Build a recurrent neural network model, using an architecture of your choosing.\n",
        "Use the one-hot embedding of each character as input to your recurrent network.\n",
        "Use one or more fully-connected layers to make the prediction based on your\n",
        "recurrent network output.\n",
        "\n",
        "Instead of using the RNN output value for the final token, another often used\n",
        "strategy is to max-pool over the entire output array. That is, instead of calling\n",
        "something like:\n",
        "\n",
        "```\n",
        "out, _ = self.rnn(x)\n",
        "self.fc(out[:, -1, :])\n",
        "```\n",
        "\n",
        "where `self.rnn` is an `nn.RNN`, `nn.GRU`, or `nn.LSTM` module, and `self.fc` is a\n",
        "fully-connected\n",
        "layer, we use:\n",
        "\n",
        "```\n",
        "out, _ = self.rnn(x)\n",
        "self.fc(torch.max(out, dim=1)[0])\n",
        "```\n",
        "\n",
        "This works reasonably in practice. An even better alternative is to concatenate the\n",
        "max-pooling and average-pooling of the RNN outputs:\n",
        "\n",
        "```\n",
        "out, _ = self.rnn(x)\n",
        "out = torch.cat([torch.max(out, dim=1)[0],\n",
        "                 torch.mean(out, dim=1)], dim=1)\n",
        "self.fc(out)\n",
        "```\n",
        "\n",
        "We encourage you to try out all these options. The way you pool the RNN outputs\n",
        "is one of the \"hyperparameters\" that you can choose to tune later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jHl1p_Wwa905",
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6be04ed1-df0d-417c-e2ed-a19cc3bcf3ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "tensor([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]])\n"
          ]
        }
      ],
      "source": [
        "# You might find this code helpful for obtaining\n",
        "# PyTorch one-hot vectors.\n",
        "\n",
        "ident = torch.eye(10)\n",
        "print(ident[0]) # one-hot vector\n",
        "print(ident[1]) # one-hot vector\n",
        "x = torch.tensor([[1, 2], [3, 4]])\n",
        "print(ident[x]) # one-hot vectors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, hidden_size, num_classes):\n",
        "        super(RNN, self).__init__()\n",
        "        self.name = 'rnn'\n",
        "        # construct matrix for onehot encodings\n",
        "        # its length must be the number of all possible characters\n",
        "        self.ident = torch.eye(len(text_field.vocab.itos))\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(len(text_field.vocab.itos), hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get onehot encoding of input\n",
        "        x = self.ident[x]\n",
        "        # Set an initial hidden state\n",
        "        h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
        "        # Forward propagate the RNN\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        # Pass the output of the last time step to the classifier\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "metadata": {
        "id": "6eRgCEPWTtm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKIYPl_Ba90_"
      },
      "source": [
        "## Part 3. Training [16 pt]\n",
        "\n",
        "### Part (a) [4 pt]\n",
        "\n",
        "Complete the `get_accuracy` function, which will compute the\n",
        "accuracy (rate) of your model across a dataset (e.g. validation set).\n",
        "You may modify `torchtext.data.BucketIterator` to make your computation\n",
        "faster."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this function is used to save checkpoints\n",
        "def get_model_name(name, batch_size, learning_rate, epoch):\n",
        "    \"\"\" Generate a name for the model consisting of all the hyperparameter values\n",
        "\n",
        "    Args:\n",
        "        config: Configuration object containing the hyperparameters\n",
        "    Returns:\n",
        "        path: A string with the hyperparameter name and value concatenated\n",
        "    \"\"\"\n",
        "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n",
        "                                                   batch_size,\n",
        "                                                   learning_rate,\n",
        "                                                   epoch)\n",
        "    return path"
      ],
      "metadata": {
        "id": "iV_zOpQewJsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train_rnn_network(model, train, valid, batch_size = 32, num_epochs=5, learning_rate=1e-5):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # getting the data\n",
        "    train_iter = data.BucketIterator(train,\n",
        "                                           batch_size=batch_size,\n",
        "                                           sort_key=lambda x: len(x.text), # to minimize padding\n",
        "                                           sort_within_batch=True,        # sort within each batch\n",
        "                                           repeat=False)                  # repeat the iterator for many epochs\n",
        "    val_iter = data.BucketIterator(valid,\n",
        "                                           batch_size=batch_size,\n",
        "                                           sort_key=lambda x: len(x.text), # to minimize padding\n",
        "                                           sort_within_batch=True,        # sort within each batch\n",
        "                                           repeat=False)                  # repeat the iterator for many epochs\n",
        "\n",
        "\n",
        "    train_losses, val_losses, train_acc, valid_acc = [], [], [], []\n",
        "    epochs = []\n",
        "    for epoch in range(num_epochs):\n",
        "        # train loss\n",
        "        for batch in train_iter:\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(batch.text)\n",
        "            train_loss = criterion(pred, batch.label)\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # validation loss\n",
        "        for batch in val_iter:\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(batch.text)\n",
        "            val_loss = criterion(pred, batch.label)\n",
        "\n",
        "        train_losses.append(float(train_loss))\n",
        "        val_losses.append(float(val_loss))\n",
        "        epochs.append(epoch)\n",
        "        train_acc.append(get_accuracy(model, train_iter))\n",
        "        valid_acc.append(get_accuracy(model, val_iter))\n",
        "\n",
        "        print(\"Epoch {}; Train Loss {}; Train Acc {}; Val Loss {}; Val Acc {}\".format(\n",
        "              epoch+1, train_losses[-1], train_acc[-1], val_losses[-1], valid_acc[-1]))\n",
        "\n",
        "        # Save the current model (checkpoint) to a file\n",
        "        model_path = get_model_name(model.name, batch_size, learning_rate, epoch)\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    # plotting\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(epochs, train_losses, label=\"Train\")\n",
        "    plt.plot(epochs, val_losses, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(epochs, train_acc, label=\"Train\")\n",
        "    plt.plot(epochs, valid_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ofksJwjSPhM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(model, data_iter):\n",
        "    correct, total = 0, 0\n",
        "    for batch in data_iter:\n",
        "        output = model(batch.text)\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(batch.label.view_as(pred)).sum().item()\n",
        "        total += batch.label.shape[0]\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "43vJ_SGYPg7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlxlcAC1a91C"
      },
      "source": [
        "### Part (b) [4 pt]\n",
        "\n",
        "Train your model. Plot the training curve of your final model.\n",
        "Your training curve should have the training/validation loss and\n",
        "accuracy plotted periodically.\n",
        "\n",
        "Note: Not all of your batches will have the same batch size.\n",
        "In particular, if your training set does not divide evenly by\n",
        "your batch size, there will be a batch that is smaller than\n",
        "the rest."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the training curve of my final model. It was obtained using Hyperparameter Set 4 which is described in Part (c). I chose this model as the best because it gave me the highest validation accuracy of `0.979`."
      ],
      "metadata": {
        "id": "BDS4tJNsGOhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN_hidden(100, 2)\n",
        "train_rnn_network(model, train_data, val_data, batch_size = 32, num_epochs=20, learning_rate=1e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 940
        },
        "outputId": "22319821-f853-4597-9abd-3a9138268a4e",
        "id": "VoFEhW8RGMOy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1; Train Loss 0.7435335516929626; Train Acc 0.5297628917260819; Val Loss 0.673870861530304; Val Acc 0.15426008968609867\n",
            "Epoch 2; Train Loss 0.385085791349411; Train Acc 0.8322002984579672; Val Loss 0.6867537498474121; Val Acc 0.6887892376681615\n",
            "Epoch 3; Train Loss 0.4578331708908081; Train Acc 0.8962029514176754; Val Loss 0.3786284029483795; Val Acc 0.9461883408071748\n",
            "Epoch 4; Train Loss 0.2727833390235901; Train Acc 0.9384844967667053; Val Loss 0.44817766547203064; Val Acc 0.9219730941704036\n",
            "Epoch 5; Train Loss 0.18146400153636932; Train Acc 0.9291991377880948; Val Loss 0.2517603635787964; Val Acc 0.9533632286995516\n",
            "Epoch 6; Train Loss 0.05240238457918167; Train Acc 0.9532415851434256; Val Loss 0.37246936559677124; Val Acc 0.9363228699551569\n",
            "Epoch 7; Train Loss 0.12309063225984573; Train Acc 0.9527441551981429; Val Loss 0.14449335634708405; Val Acc 0.9533632286995516\n",
            "Epoch 8; Train Loss 0.14242567121982574; Train Acc 0.9540706350522301; Val Loss 0.20391632616519928; Val Acc 0.9345291479820628\n",
            "Epoch 9; Train Loss 0.1216287761926651; Train Acc 0.9610346542861881; Val Loss 0.16502898931503296; Val Acc 0.9479820627802691\n",
            "Epoch 10; Train Loss 0.14324963092803955; Train Acc 0.9631901840490797; Val Loss 0.15602286159992218; Val Acc 0.9560538116591928\n",
            "Epoch 11; Train Loss 0.19463521242141724; Train Acc 0.939147736693749; Val Loss 0.04715672880411148; Val Acc 0.9739910313901345\n",
            "Epoch 12; Train Loss 0.06156005710363388; Train Acc 0.9643508539214061; Val Loss 0.10408784449100494; Val Acc 0.9721973094170404\n",
            "Epoch 13; Train Loss 0.04244401678442955; Train Acc 0.9645166639031669; Val Loss 0.08977954834699631; Val Acc 0.967713004484305\n",
            "Epoch 14; Train Loss 0.01874495856463909; Train Acc 0.9641850439396452; Val Loss 0.05784665420651436; Val Acc 0.9748878923766816\n",
            "Epoch 15; Train Loss 0.07928509265184402; Train Acc 0.9583816945780136; Val Loss 0.18968349695205688; Val Acc 0.9210762331838565\n",
            "Epoch 16; Train Loss 0.21704021096229553; Train Acc 0.969490963355994; Val Loss 0.03464546799659729; Val Acc 0.9695067264573991\n",
            "Epoch 17; Train Loss 0.2649664580821991; Train Acc 0.9620295141767534; Val Loss 0.34857046604156494; Val Acc 0.9255605381165919\n",
            "Epoch 18; Train Loss 0.6748915910720825; Train Acc 0.9696567733377549; Val Loss 0.18197289109230042; Val Acc 0.9775784753363229\n",
            "Epoch 19; Train Loss 0.013492913916707039; Train Acc 0.9691593433924722; Val Loss 0.11376896500587463; Val Acc 0.9757847533632287\n",
            "Epoch 20; Train Loss 0.043772123754024506; Train Acc 0.9605372243409053; Val Loss 0.02382463589310646; Val Acc 0.979372197309417\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE3eRkDAa91F"
      },
      "source": [
        "### Part (c) [4 pt]\n",
        "\n",
        "Choose at least 4 hyperparameters to tune. Explain how you tuned the hyperparameters.\n",
        "You don't need to include your training curve for every model you trained.\n",
        "Instead, explain what hyperparemters you tuned, what the best validation accuracy was,\n",
        "and the reasoning behind the hyperparameter decisions you made.\n",
        "\n",
        "For this assignment, you should tune more than just your learning rate and epoch.\n",
        "Choose at least 2 hyperparameters that are unrelated to the optimizer."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter Set 1**\n",
        "\n",
        "For the first hyperparameter set I changed the model architecture. I used\n",
        "```\n",
        "out, _ = self.rnn(x)\n",
        "self.fc(out[:, -1, :])\n",
        "```\n",
        "at the output of the RNN.\n",
        "\n",
        "I used a batch size of 32, and a learning rate of `1e-4`. This gave good results as I obtained a validation accuracy as high as `0.96`. However, to do better, I will try max-pooling over the output array."
      ],
      "metadata": {
        "id": "UBec2lS82S6e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CVtf7CJCa91D",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "model = RNN(50, 2)\n",
        "\n",
        "train_rnn_network(model, train_data, val_data, batch_size = 32, num_epochs=20, learning_rate=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter Set 2**\n",
        "\n"
      ],
      "metadata": {
        "id": "8AoWg2pq2XFK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this hyperparameter set I changed the model architecture. I used\n",
        "```\n",
        "out, _ = self.rnn(x)\n",
        "self.fc(torch.max(out, dim=1)[0])\n",
        "```\n",
        "at the output of the RNN.\n",
        "\n",
        "This gave me better results than hyperparameter set 1 as I obtained a validation accuracy as high as `0.973`. However, to see if I can do better I will try concatenating the\n",
        "max-pooling and average-pooling of the RNN outputs.\n",
        "\n"
      ],
      "metadata": {
        "id": "KglbZdwgDZ1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_pool(nn.Module):\n",
        "    def __init__(self, hidden_size, num_classes):\n",
        "        super(RNN_pool, self).__init__()\n",
        "        self.name = 'rnn_pool'\n",
        "        # construct matrix for onehot encodings\n",
        "        # its length must be the number of all possible characters\n",
        "        self.ident = torch.eye(len(text_field.vocab.itos))\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(len(text_field.vocab.itos), hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get onehot encoding of input\n",
        "        x = self.ident[x]\n",
        "        # Set an initial hidden state\n",
        "        h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
        "        # Forward propagate the RNN\n",
        "        out, _ = self.rnn(x)\n",
        "        out, _ = self.rnn(x)\n",
        "        out = self.fc(torch.max(out, dim=1)[0])\n",
        "        return out"
      ],
      "metadata": {
        "id": "47mdMc0K4FRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN_pool(50, 2)\n",
        "train_rnn_network(model, train_data, val_data, batch_size = 32, num_epochs=20, learning_rate=1e-4)"
      ],
      "metadata": {
        "id": "79RLMx4w4QEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter Set 3**\n",
        "\n"
      ],
      "metadata": {
        "id": "PduGWE_f2XOy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this hyperparameter set I changed the model architecture. I used\n",
        "```\n",
        "out, _ = self.rnn(x)\n",
        "out = torch.cat([torch.max(out, dim=1)[0],\n",
        "                 torch.mean(out, dim=1)], dim=1)\n",
        "self.fc(out)\n",
        "```\n",
        "at the output of the RNN.\n",
        "\n",
        "This gave me the best results so far as I obtained a final validation accuracy of `0.978`."
      ],
      "metadata": {
        "id": "k22VvzJ6EG-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_concat(nn.Module):\n",
        "    def __init__(self, hidden_size, num_classes):\n",
        "        super(RNN_concat, self).__init__()\n",
        "        self.name = 'rnn_concat'\n",
        "        # construct matrix for onehot encodings\n",
        "        # its length must be the number of all possible characters\n",
        "        self.ident = torch.eye(len(text_field.vocab.itos))\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(len(text_field.vocab.itos), hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size*2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get onehot encoding of input\n",
        "        x = self.ident[x]\n",
        "        # Set an initial hidden state\n",
        "        h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
        "        # Forward propagate the RNN\n",
        "        out, _ = self.rnn(x)\n",
        "        out = torch.cat([torch.max(out, dim=1)[0],\n",
        "                 torch.mean(out, dim=1)], dim=1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "wn6oTrFGxVdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN_concat(50, 2)\n",
        "train_rnn_network(model, train_data, val_data, batch_size = 32, num_epochs=20, learning_rate=1e-4)"
      ],
      "metadata": {
        "id": "csT5bLfkySKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter Set 4**\n",
        "\n",
        "For this hyperparameter set I changed the model architecture to see if I can somehow improve. I increased `hidden_size` to 100.\n",
        "This did improve the validation accuracy as its final value is now `0.979`. Thus, I will choose this as my best model.\n",
        "\n",
        "It should be noted that I used the concatenated RNN architecture here as well.\n",
        "\n"
      ],
      "metadata": {
        "id": "FQBfp9Hj2W2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_hidden(nn.Module):\n",
        "    def __init__(self, hidden_size, num_classes):\n",
        "        super(RNN_hidden, self).__init__()\n",
        "        self.name = 'rnn_hidden'\n",
        "        # construct matrix for onehot encodings\n",
        "        # its length must be the number of all possible characters\n",
        "        self.ident = torch.eye(len(text_field.vocab.itos))\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(len(text_field.vocab.itos), hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size*2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get onehot encoding of input\n",
        "        x = self.ident[x]\n",
        "        # Set an initial hidden state\n",
        "        h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
        "        # Forward propagate the RNN\n",
        "        out, _ = self.rnn(x)\n",
        "        out = torch.cat([torch.max(out, dim=1)[0],\n",
        "                 torch.mean(out, dim=1)], dim=1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "jur3G5fYE4_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN_hidden(100, 2)\n",
        "train_rnn_network(model, train_data, val_data, batch_size = 32, num_epochs=20, learning_rate=1e-4)"
      ],
      "metadata": {
        "id": "oIAA9JkCFEJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7DY56rKa91I"
      },
      "source": [
        "### Part (d) [2 pt]\n",
        "\n",
        "Before we deploy a machine learning model, we usually want to have a better understanding\n",
        "of how our model performs beyond its validation accuracy. An important metric to track is\n",
        "*how well our model performs in certain subsets of the data*.\n",
        "\n",
        "In particular, what is the model's error rate amongst data with negative labels?\n",
        "This is called the **false positive rate**.\n",
        "\n",
        "What about the model's error rate amongst data with positive labels?\n",
        "This is called the **false negative rate**.\n",
        "\n",
        "Report your final model's false positive and false negative rate across the\n",
        "validation set."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using model from hyperparameter set 4\n",
        "model_path = get_model_name('rnn_hidden', batch_size=32, learning_rate=1e-4, epoch=19)\n",
        "state = torch.load(model_path)\n",
        "model.load_state_dict(state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAE8ebs8L_Hs",
        "outputId": "4487865d-efae-4604-8b7c-9478d46be698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7ggbQSdba91J",
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18694f38-31df-4ce1-9b82-dc307d49a677"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False positive rate across validation set: 1.0362694300518172 %\n",
            "False negative rate across validation set: 7.9999999999999964 %\n"
          ]
        }
      ],
      "source": [
        "# Create a Dataset of only spam validation examples\n",
        "valid_spam = data.Dataset(\n",
        "    [e for e in val_data.examples if e.label == 1],\n",
        "    val_data.fields)\n",
        "\n",
        "val_spam_iter = data.BucketIterator(valid_spam,\n",
        "                                           batch_size=32,\n",
        "                                           sort_key=lambda x: len(x.text), # to minimize padding\n",
        "                                           sort_within_batch=True,        # sort within each batch\n",
        "                                           repeat=False)                  # repeat the iterator for many epochs\n",
        "\n",
        "# Create a Dataset of only non-spam validation examples\n",
        "valid_nospam = data.Dataset(\n",
        "    [e for e in val_data.examples if e.label == 0],\n",
        "    val_data.fields)\n",
        "\n",
        "val_nospam_iter = data.BucketIterator(valid_nospam,\n",
        "                                           batch_size=32,\n",
        "                                           sort_key=lambda x: len(x.text), # to minimize padding\n",
        "                                           sort_within_batch=True,        # sort within each batch\n",
        "                                           repeat=False)                  # repeat the iterator for many epochs\n",
        "\n",
        "# number of false positives is the number of non-spam identified as spam\n",
        "# check for\n",
        "false_positive_rate = 1 - get_accuracy(model, val_nospam_iter)\n",
        "print('False positive rate across validation set: {} %'.format(false_positive_rate*100))\n",
        "\n",
        "# false negatives are spam identified as non-spam\n",
        "false_negative_rate = 1 - get_accuracy(model, val_spam_iter)\n",
        "print('False negative rate across validation set: {} %'.format(false_negative_rate*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1iRteb3a91O"
      },
      "source": [
        "### Part (e) [2 pt]\n",
        "\n",
        "The impact of a false positive vs a false negative can be drastically different.\n",
        "If our spam detection algorithm was deployed on your phone, what is the impact\n",
        "of a false positive on the phone's user? What is the impact of a false negative?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A false positive would mean that one of the user's non-spam messages, for example a message from a friend, would be identified as spam and probably deleted. This impact is not so bad as the friend would probably send another text or call the user. No harm comes to the user.\n",
        "\n",
        "A false negative would mean that a spam message would be identified as non-spam and thus may lead to the user being scammed/phished or harmed in some way. This has a big impact as the user is being harmed."
      ],
      "metadata": {
        "id": "eqbP149-NtHJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gznefulsa91V"
      },
      "source": [
        "## Part 4. Evaluation [11 pt]\n",
        "\n",
        "### Part (a) [1 pt]\n",
        "\n",
        "Report the final test accuracy of your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "D5L5D-A1a91W",
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90fbd2a5-e8d9-49c6-ffd8-31203d307400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final test accuracy: 0.9784560143626571\n"
          ]
        }
      ],
      "source": [
        "# getting test data\n",
        "test_iter = data.BucketIterator(test_data,\n",
        "                                           batch_size=32,\n",
        "                                           sort_key=lambda x: len(x.text), # to minimize padding\n",
        "                                           sort_within_batch=True,        # sort within each batch\n",
        "                                           repeat=False)                  # repeat the iterator for many epochs\n",
        "\n",
        "# using model from hyperparameter set 4\n",
        "model_path = get_model_name('rnn_hidden', batch_size=32, learning_rate=1e-4, epoch=19)\n",
        "state = torch.load(model_path)\n",
        "model.load_state_dict(state)\n",
        "\n",
        "test_acc = get_accuracy(model, test_iter)\n",
        "print('Final test accuracy: {}'.format(test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Hjmd8rca91Y"
      },
      "source": [
        "### Part (b) [3 pt]\n",
        "\n",
        "Report the false positive rate and false negative rate of your model across the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GFiAKztJa91Z",
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3076a0f-0bce-47f1-8ca2-41ab37b3ab7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False positive rate across test set: 1.3471502590673534 %\n",
            "False negative rate across test set: 8.7248322147651 %\n"
          ]
        }
      ],
      "source": [
        "# Create a Dataset of only spam validation examples\n",
        "test_spam = data.Dataset(\n",
        "    [e for e in test_data.examples if e.label == 1],\n",
        "    test_data.fields)\n",
        "\n",
        "test_spam_iter = data.BucketIterator(test_spam,\n",
        "                                           batch_size=32,\n",
        "                                           sort_key=lambda x: len(x.text), # to minimize padding\n",
        "                                           sort_within_batch=True,        # sort within each batch\n",
        "                                           repeat=False)                  # repeat the iterator for many epochs\n",
        "\n",
        "# Create a Dataset of only non-spam validation examples\n",
        "test_nospam = data.Dataset(\n",
        "    [e for e in test_data.examples if e.label == 0],\n",
        "    test_data.fields)\n",
        "\n",
        "test_nospam_iter = data.BucketIterator(test_nospam,\n",
        "                                           batch_size=32,\n",
        "                                           sort_key=lambda x: len(x.text), # to minimize padding\n",
        "                                           sort_within_batch=True,        # sort within each batch\n",
        "                                           repeat=False)                  # repeat the iterator for many epochs\n",
        "\n",
        "# number of false positives is the number of non-spam identified as spam\n",
        "# check for\n",
        "false_positive_rate = 1 - get_accuracy(model, test_nospam_iter)\n",
        "print('False positive rate across test set: {} %'.format(false_positive_rate*100))\n",
        "\n",
        "# false negatives are spam identified as non-spam\n",
        "false_negative_rate = 1 - get_accuracy(model, test_spam_iter)\n",
        "print('False negative rate across test set: {} %'.format(false_negative_rate*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jGHtQFpa91b"
      },
      "source": [
        "### Part (c) [3 pt]\n",
        "\n",
        "What is your model's prediction of the **probability** that\n",
        "the SMS message \"machine learning is sooo cool!\" is spam?\n",
        "\n",
        "Hint: To begin, use `text_field.vocab.stoi` to look up the index\n",
        "of each character in the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_2nSJq8a91b",
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cb5d95c-07c4-4071-80aa-697d6aa61dc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model predicts the message is spam with a probability of 2.8052587509155273 %\n"
          ]
        }
      ],
      "source": [
        "msg = \"machine learning is sooo cool!\"\n",
        "\n",
        "# using model from hyperparameter set 4\n",
        "model_path = get_model_name('rnn_hidden', batch_size=32, learning_rate=1e-4, epoch=19)\n",
        "state = torch.load(model_path)\n",
        "model.load_state_dict(state)\n",
        "\n",
        "# looking up the index of each character\n",
        "# vector to store the indices\n",
        "indices = []\n",
        "for letter in msg:\n",
        "  indices.append(text_field.vocab.stoi[letter])\n",
        "\n",
        "# converting to a tensor to pass to model\n",
        "indices_tensor = torch.tensor(indices)\n",
        "\n",
        "# adding a dimension to be compatible with model and obtaining prediction\n",
        "prediction = model(indices_tensor.unsqueeze(0))\n",
        "\n",
        "# obtaining the probabilities using softmax\n",
        "probability = F.softmax(prediction, dim=1)\n",
        "\n",
        "# obtaining the prediction of the probability of a spam message\n",
        "print('The model predicts the message is spam with a probability of {} %'.format(probability[0][1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QD1zgYJpa91f"
      },
      "source": [
        "### Part (d) [4 pt]\n",
        "\n",
        "Do you think detecting spam is an easy or difficult task?\n",
        "\n",
        "Since machine learning models are expensive to train and deploy, it is very\n",
        "important to compare our models against baseline models: a simple\n",
        "model that is easy to build and inexpensive to run that we can compare our\n",
        "recurrent neural network model against.\n",
        "\n",
        "Explain how you might build a simple baseline model. This baseline model\n",
        "can be a simple neural network (with very few weights), a hand-written algorithm,\n",
        "or any other strategy that is easy to build and test.\n",
        "\n",
        "**Do not actually build a baseline model. Instead, provide instructions on\n",
        "how to build it.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detecting spam can sometimes be a difficult task. Some scammers have become very skilled and it sometimes hard to know if a message or email is spam or not.\n",
        "\n",
        "**Baseline model**\n",
        "\n",
        "You can use a rules-based algorithm for the baseline model.\n",
        "\n",
        "You can associate certain words/phrases with spam messages, such as \"Free money\" or \"Congrats you won $1000\". So once a message contains these words or phrases, the algorithm will automatically classify it as spam.\n",
        "\n",
        "First build a list of words/phrases (from your knowledge/internet) that, once included in a message, will identify the message as spam.\n",
        "\n",
        "The algorithm can first parse the message, looking for these key words/phrases.\n",
        "\n",
        "If the message includes such words/phrases, identify it as spam."
      ],
      "metadata": {
        "id": "pvsz87S6Ppbx"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}